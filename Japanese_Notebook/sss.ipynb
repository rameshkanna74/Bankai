{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boombox baby\n",
      "https://youtu.be/lKitLqiM-O0\n",
      "寛和\n"
     ]
    }
   ],
   "source": [
    "print(\"Boombox baby\")\n",
    "print(\"https://youtu.be/lKitLqiM-O0\")\n",
    "print(\"寛和\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Read the HTML file\n",
    "with open(\"test.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find the specific div by class name\n",
    "div = soup.find(\"div\", class_=\"last_episodes\")\n",
    "\n",
    "# Check if the div exists\n",
    "if div:\n",
    "    # Find all anchor tags within the div\n",
    "    anchors = div.find_all(\"a\")\n",
    "\n",
    "    # Print out the href attributes of the anchor tags\n",
    "    for anchor in anchors:\n",
    "        print(anchor.get(\"href\"))\n",
    "else:\n",
    "    print(\"No div with class 'last_episodes' found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_titles = [\n",
    "    \"2-5-jigen-no-ririsa\",\n",
    "    \"anti-routine-system-season-2\",\n",
    "    \"date-a-live-v-dub\",\n",
    "    \"divine-heros-skyfall-system\",\n",
    "    \"emperor-son-in-law\",\n",
    "    \"i-have-a-little-too-much-nascent-souls\",\n",
    "    \"i-really-dont-want-to-be-the-first\",\n",
    "    \"i-was-forced-by-the-system-to-become-a-villain\",\n",
    "    \"im-stuck-on-the-same-day-for-a-thousand-years\",\n",
    "    \"kekkon-yubiwa-monogatari\",\n",
    "    \"kekkon-yubiwa-monogatari-dub\",\n",
    "    \"logging-10000-years-into-the-future\",\n",
    "    \"lucky-me-i-secretly-cultivated-for-1000-years\",\n",
    "    \"mato-seihei-no-slave\",\n",
    "    \"mato-seihei-no-slave-dub\",\n",
    "    \"my-apocalyptic-miss\",\n",
    "    \"my-seven-sisters-are-unparalleled\",\n",
    "    \"my-wife-is-a-heavenly-big-shot\",\n",
    "    \"nightwatcher\",\n",
    "    \"starting-out-with-max-favorability\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# List of anime titles to get direct download links for\n",
    "anime_titles = [\n",
    "    \"2-5-jigen-no-ririsa\",\n",
    "    \"anti-routine-system-season-2\",\n",
    "    \"date-a-live-v-dub\",\n",
    "    \"divine-heros-skyfall-system\",\n",
    "    \"emperor-son-in-law\",\n",
    "    \"i-have-a-little-too-much-nascent-souls\",\n",
    "    \"i-really-dont-want-to-be-the-first\",\n",
    "    \"i-was-forced-by-the-system-to-become-a-villain\",\n",
    "    \"im-stuck-on-the-same-day-for-a-thousand-years\",\n",
    "    \"kekkon-yubiwa-monogatari\",\n",
    "    \"kekkon-yubiwa-monogatari-dub\",\n",
    "    \"logging-10000-years-into-the-future\",\n",
    "    \"lucky-me-i-secretly-cultivated-for-1000-years\",\n",
    "    \"mato-seihei-no-slave\",\n",
    "    \"mato-seihei-no-slave-dub\",\n",
    "    \"my-apocalyptic-miss\",\n",
    "    \"my-seven-sisters-are-unparalleled\",\n",
    "    \"my-wife-is-a-heavenly-big-shot\",\n",
    "    \"nightwatcher\",\n",
    "    \"starting-out-with-max-favorability\",\n",
    "]\n",
    "\n",
    "\n",
    "# Function to run senpcli command and get direct download links\n",
    "def get_direct_download_links(title):\n",
    "    command = [\n",
    "        \"senpcli\",\n",
    "        \"-ddl\",  # Option to get direct download links\n",
    "        \"-q\",\n",
    "        \"480p\",  # Quality: 480p\n",
    "        \"-sd\",\n",
    "        \"sub\",  # Subbed version\n",
    "        title,\n",
    "    ]\n",
    "    try:\n",
    "        # Execute the command and capture the output\n",
    "        result = subprocess.run(command, check=True, text=True, capture_output=True)\n",
    "        print(f\"Direct download links for: {title}\")\n",
    "        print(result.stdout)  # Print the output of the command\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred while getting DDL for {title}: {e}\")\n",
    "\n",
    "\n",
    "# Iterate over the list of anime titles and get direct download links for each\",\n",
    "for title in anime_titles:\n",
    "    print(title)\n",
    "    # get_direct_download_links(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of anime titles to download\n",
    "anime_titles = [\n",
    "    # \"isekai-ojisan\",\n",
    "    # \"hazurewaku-no-joutai-ijou-skill-de-saikyou-ni-natta-ore-ga-subete-wo-juurin-suru-made\",\n",
    "    # \"tsugumomo\",\n",
    "    # \"Sekirei\",\n",
    "    # \"freezing\",\n",
    "    # \"mahou-sensei-negima\",\n",
    "    # \"date-a-live\",\n",
    "    # \"date-a-live-ii\",\n",
    "    # \"date-a-live-iii\",\n",
    "    # \"date-a-live-iv\",\n",
    "    # \"date-a-live-v\",\n",
    "    # \"High-School-DxD\",\n",
    "    # \"\",\n",
    "]\n",
    "\n",
    "\n",
    "# Function to run senpcli command\n",
    "def run_senpcli(title):\n",
    "    command = [\n",
    "        \"senpcli\",\n",
    "        \"-s\",\n",
    "        \"gogo\",  # Site: gogo\n",
    "        \"-q\",\n",
    "        \"480p\",  # Quality: 480p\n",
    "        \"-sd\",\n",
    "        \"sub\",  # Subbed version\n",
    "        # \"-se\",\n",
    "        # \"1\",  # Start episode (1)\n",
    "        # \"-ee\",\n",
    "        # \"1000\",  # End episode (1000) - adjust if needed\n",
    "        title,\n",
    "    ]\n",
    "    try:\n",
    "        # Execute the command and wait for it to complete\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Download started for: {title}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred while downloading {title}: {e}\")\n",
    "\n",
    "\n",
    "# Iterate over the list of anime titles and download each\n",
    "for title in anime_titles:\n",
    "    run_senpcli(title)\n",
    "    # print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   AniList\n",
      "  </title>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"ie=edge\" http-equiv=\"x-ua-compatible\"/>\n",
      "  <meta content=\"block-all-mixed-content\" http-equiv=\"Content-Security-Policy\"/>\n",
      "  <meta content=\"width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no\" name=\"viewport\"/>\n",
      "  <meta content=\"AniList\" property=\"og:site_name\"/>\n",
      "  <meta content=\"@AniListco\" name=\"twitter:site\"/>\n",
      "  <script>\n",
      "   window.al_token = \"Z62palI1ochidj0Nn1CVdn1pNzncKWyObTTx2ZwJ\";\n",
      "  </script>\n",
      "  <link href=\"//fonts.googleapis.com/css?family=Roboto:300,400,500,700\" rel=\"stylesheet\"/>\n",
      "  <link as=\"style\" href=\"https://fonts.googleapis.com/css?family=Overpass:400,600,700,800\" rel=\"preload\"/>\n",
      "  <link href=\"https://fonts.googleapis.com/css?family=Overpass:400,600,700,800\" rel=\"stylesheet\"/>\n",
      "  <link href=\"/img/icons/favicon-32x32.png\" rel=\"icon\" sizes=\"32x32\" type=\"image/png\"/>\n",
      "  <link href=\"/img/icons/favicon-16x16.png\" rel=\"icon\" sizes=\"16x16\" type=\"image/png\"/>\n",
      "  <link href=\"/manifest.json\" rel=\"manifest\"/>\n",
      "  <meta content=\"#2b2d42\" name=\"theme-color\"/>\n",
      "  <meta content=\"yes\" name=\"apple-mobile-web-app-capable\"/>\n",
      "  <meta content=\"black\" name=\"apple-mobile-web-app-status-bar-style\"/>\n",
      "  <meta content=\"AniList\" name=\"apple-mobile-web-app-title\"/>\n",
      "  <link href=\"/img/icons/apple-touch-icon.png\" rel=\"apple-touch-icon\" sizes=\"180x180\"/>\n",
      "  <link color=\"#1f2631\" href=\"/img/icons/safari-pinned-tab.svg\" rel=\"mask-icon\"/>\n",
      "  <meta content=\"/img/icons/msapplication-icon-144x144.png\" name=\"msapplication-TileImage\"/>\n",
      "  <meta content=\"#1f2631\" name=\"msapplication-TileColor\"/>\n",
      "  <script async=\"\" data-mode=\"scan\" data-site-id=\"620b7689c60cb1644bf9d153\" src=\"https://hb.vntsm.com/v3/live/ad-manager.min.js\">\n",
      "  </script>\n",
      "  <script async=\"\" defer=\"\" src=\"https://www.google.com/recaptcha/api.js?onload=vueRecaptchaApiLoaded&amp;render=explicit\">\n",
      "  </script>\n",
      "  <link href=\"/css/forum.e234bf12.css\" rel=\"prefetch\"/>\n",
      "  <link href=\"/css/lists.26134e96.css\" rel=\"prefetch\"/>\n",
      "  <link href=\"/css/settings.38484e79.css\" rel=\"prefetch\"/>\n",
      "  <link href=\"/css/staff.4dd40831.css\" rel=\"prefetch\"/>\n",
      "  <link href=\"/css/stats.4661673b.css\" rel=\"prefetch\"/>\n",
      "  <link href=\"/css/submissions.91d063e7.css\" rel=\"prefetch\"/>\n",
      "  <link href=\"/js/forum.b25f7e70.js\" rel=\"prefetch\"/>\n",
      "  <link href=\"/js/lists.7855a751.js\" rel=\"prefetch\"/>\n",
      "  <link href=\"/js/settings.06b56914.js\" rel=\"prefetch\"/>\n",
      "  <link href=\"/js/settings~submissions.be373d82.js\" rel=\"prefetch\"/>\n",
      "  <link href=\"/js/staff.cd70c0f5.js\" rel=\"prefetch\"/>\n",
      "  <link href=\"/js/stats.e9fea624.js\" rel=\"prefetch\"/>\n",
      "  <link href=\"/js/submissions.2a575eeb.js\" rel=\"prefetch\"/>\n",
      "  <link as=\"style\" href=\"/css/chunk-vendors.3826fb1f.css\" rel=\"preload\"/>\n",
      "  <link as=\"style\" href=\"/css/main.212a59a5.css\" rel=\"preload\"/>\n",
      "  <link as=\"script\" href=\"/js/chunk-vendors.c284cf74.js\" rel=\"modulepreload\"/>\n",
      "  <link as=\"script\" href=\"/js/main.bde67891.js\" rel=\"modulepreload\"/>\n",
      "  <link href=\"/css/chunk-vendors.3826fb1f.css\" rel=\"stylesheet\"/>\n",
      "  <link href=\"/css/main.212a59a5.css\" rel=\"stylesheet\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <noscript>\n",
      "   <div class=\"noscript\">\n",
      "    Sorry, AniList requires Javascript.\n",
      "    <br/>\n",
      "    Please enable Javascript or\n",
      "    <a href=\"http://outdatedbrowser.com\">\n",
      "     upgrade to a modern web browser\n",
      "    </a>\n",
      "    .\n",
      "   </div>\n",
      "  </noscript>\n",
      "  <div class=\"noscript modern-browser\" style=\"display: none\">\n",
      "   Sorry, AniList requires a modern browser.\n",
      "   <br/>\n",
      "   Please\n",
      "   <a href=\"http://outdatedbrowser.com\">\n",
      "    upgrade to a newer web browser\n",
      "   </a>\n",
      "   .\n",
      "  </div>\n",
      "  <div id=\"app\">\n",
      "  </div>\n",
      "  <script src=\"/js/chunk-vendors.c284cf74.js\" type=\"module\">\n",
      "  </script>\n",
      "  <script src=\"/js/main.bde67891.js\" type=\"module\">\n",
      "  </script>\n",
      "  <script>\n",
      "   !function(){var e=document,t=e.createElement(\"script\");if(!(\"noModule\"in t)&&\"onbeforeload\"in t){var n=!1;e.addEventListener(\"beforeload\",function(e){if(e.target===t)n=!0;else if(!e.target.hasAttribute(\"nomodule\")||!n)return;e.preventDefault()},!0),t.type=\"module\",t.src=\".\",e.head.appendChild(t),t.remove()}}();\n",
      "  </script>\n",
      "  <script nomodule=\"\" src=\"/js/chunk-vendors-legacy.34295f08.js\">\n",
      "  </script>\n",
      "  <script nomodule=\"\" src=\"/js/main-legacy.c4ce72c1.js\">\n",
      "  </script>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL of the site you want to scrape\n",
    "url = 'https://anilist.co/'\n",
    "\n",
    "# Define the headers to mimic a request from a modern web browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1'\n",
    "}\n",
    "\n",
    "# Make the request to the URL with the defined headers\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Print the prettified HTML (or process it as needed)\n",
    "    print(soup.prettify())\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml[html_clean] in ./Bankai/lib/python3.11/site-packages (5.3.0)\n",
      "Collecting lxml-html-clean (from lxml[html_clean])\n",
      "  Downloading lxml_html_clean-0.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading lxml_html_clean-0.2.2-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: lxml-html-clean\n",
      "Successfully installed lxml-html-clean-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"lxml[html_clean]\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Render JavaScript\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get the page content\u001b[39;00m\n\u001b[1;32m     14\u001b[0m page_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mhtml\n",
      "File \u001b[0;32m~/Documents/Anki/notebook/Bankai/lib/python3.11/site-packages/requests_html.py:586\u001b[0m, in \u001b[0;36mHTML.render\u001b[0;34m(self, retries, script, wait, scrolldown, sleep, reload, timeout, keep_page)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, retries: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, script: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, wait: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, scrolldown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sleep: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, reload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, timeout: Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8.0\u001b[39m, keep_page: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Reloads the response in Chromium, and replaces HTML content\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m    with an updated version, with JavaScript executed.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m    Chromium into your home directory (``~/.pyppeteer``).\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbrowser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbrowser\u001b[49m  \u001b[38;5;66;03m# Automatically create a event loop and browser\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;66;03m# Automatically set Reload to False, if example URL is being used.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Anki/notebook/Bankai/lib/python3.11/site-packages/requests_html.py:729\u001b[0m, in \u001b[0;36mHTMLSession.browser\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 729\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_browser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mrun_until_complete(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mbrowser)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_browser\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead."
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "# Create an HTMLSession instance\n",
    "session = HTMLSession()\n",
    "\n",
    "# Load the page\n",
    "url = 'https://anilist.co/'\n",
    "response = session.get(url)\n",
    "\n",
    "# Render JavaScript\n",
    "response.html.render()\n",
    "\n",
    "# Get the page content\n",
    "page_content = response.html.html\n",
    "\n",
    "# Use BeautifulSoup to parse the content\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "# Print or process the content\n",
    "print(soup.prettify())\n",
    "from requests_html import HTMLSessionasdfadsfada\n",
    "\n",
    "# Create an HTMLSession instance\n",
    "session = HTMLSession()\n",
    "\n",
    "# Load the page\n",
    "url = 'https://anilist.co/'\n",
    "response = session.get(url)\n",
    "\n",
    "# Render JavaScript\n",
    "response.html.render()\n",
    "\n",
    "# Get the page content\n",
    "page_content = response.html.html\n",
    "\n",
    "# Use BeautifulSoup to parse the content\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "# Print or process the content\n",
    "print(soup.prettify())\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
