{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Global objects\n",
    "vectorizer = TfidfVectorizer()\n",
    "scaler = StandardScaler()\n",
    "knn = None\n",
    "\n",
    "@app.route('/train', methods=['POST'])\n",
    "def train_model():\n",
    "    global vectorizer, scaler, knn\n",
    "\n",
    "    # Get file path from the request\n",
    "    file_path = request.json.get('file_path')\n",
    "    if not file_path:\n",
    "        return jsonify({\"error\": \"File path is required\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Read the data\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Ensure numeric column is clean\n",
    "        df[\"matricule_ocr_value\"] = pd.to_numeric(df[\"matricule_ocr_value\"], errors='coerce')\n",
    "\n",
    "        # Drop rows with invalid numeric values\n",
    "        df = df.dropna(subset=[\"matricule_ocr_value\"])\n",
    "\n",
    "        # Extract features and target\n",
    "        X_text = df[\"Full_name\"]\n",
    "        X_numeric = df[\"matricule_ocr_value\"].values.reshape(-1, 1)\n",
    "        y = df[\"Corrected_Name\"]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_text_train, X_text_test, X_numeric_train, X_numeric_test, y_train, y_test = train_test_split(\n",
    "            X_text, X_numeric, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Text feature vectorization\n",
    "        X_text_train_vectors = vectorizer.fit_transform(X_text_train)\n",
    "        X_text_test_vectors = vectorizer.transform(X_text_test)\n",
    "\n",
    "        # Numeric feature scaling\n",
    "        X_numeric_train_scaled = scaler.fit_transform(X_numeric_train)\n",
    "        X_numeric_test_scaled = scaler.transform(X_numeric_test)\n",
    "\n",
    "        # Combine text and numeric features\n",
    "        X_train_combined = np.hstack([X_text_train_vectors.toarray(), X_numeric_train_scaled])\n",
    "        X_test_combined = np.hstack([X_text_test_vectors.toarray(), X_numeric_test_scaled])\n",
    "\n",
    "        # Train KNN model\n",
    "        knn = KNeighborsClassifier(n_neighbors=1)\n",
    "        knn.fit(X_train_combined, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = knn.predict(X_test_combined)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        return jsonify({\"message\": \"Model trained successfully\", \"accuracy\": accuracy})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/predict', methods=['POST', 'GET'])\n",
    "def predict_new_data():\n",
    "    global vectorizer, scaler, knn\n",
    "\n",
    "    if knn is None:\n",
    "        return jsonify({\"error\": \"Model is not trained yet. Please train the model first.\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Get input data from the request\n",
    "        matricule_number = request.json.get('matricule_number')\n",
    "        full_name = request.json.get('full_name')\n",
    "\n",
    "        if matricule_number is None or full_name is None:\n",
    "            return jsonify({\"error\": \"Both matricule_number and full_name are required.\"}), 400\n",
    "\n",
    "        # Transform new text data using the existing vectorizer\n",
    "        new_text_vectors = vectorizer.transform([full_name])\n",
    "\n",
    "        # Scale new numeric data using the existing scaler\n",
    "        new_numeric_scaled = scaler.transform(np.array([matricule_number]).reshape(-1, 1))\n",
    "\n",
    "        # Combine new features\n",
    "        new_combined = np.hstack([new_text_vectors.toarray(), new_numeric_scaled])\n",
    "\n",
    "        # Predict using the trained KNN model\n",
    "        prediction = knn.predict(new_combined)\n",
    "\n",
    "        return jsonify({\n",
    "            \"matricule_number\": matricule_number,\n",
    "            \"full_name\": full_name,\n",
    "            \"predicted_name\": prediction[0]\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **プロフェッショナルでフォーマルな自己紹介（日本語）**\n",
    "\n",
    "初めまして、ラメシュ・カンナと申します。インドのプドゥッチェリ出身で、現在バックエンド開発を専門としております。特に **Python を用いた Django および Django Rest Framework (DRF) による REST API 開発** に強みを持ち、**PostgreSQL を活用したデータベース設計・パフォーマンス最適化** にも豊富な経験があります。\n",
    "\n",
    "これまでのキャリアにおいて、**OCR API 統合アプリケーションや e ラーニングプラットフォームのバックエンド開発** に携わり、**セキュアなユーザー認証（JWT 認証）やロールベースのアクセス制御の実装** を担当いたしました。また、**Docker や CI/CD パイプラインを活用したアプリケーションの自動デプロイ** を行い、システムのスケーラビリティと保守性の向上にも貢献しております。\n",
    "\n",
    "私の強みは、**拡張性と効率性を兼ね備えたコード設計** にあります。例えば、大規模な OCR システムの開発において、**EasyOCR、Google Document AI、Azure OCR など複数の OCR サービスを統合し、50,000 件以上の画像処理を最適化** した実績があります。また、現在は **Rust を学習** しており、アルゴリズムとデータ構造の理解を深めるため、**LeetCode で 200 問以上の問題を解き、低レイヤーのプログラミングスキルを強化** しております。\n",
    "\n",
    "技術面だけでなく、**チームとの円滑なコミュニケーション** も大切にしております。要件定義から設計・実装・テスト・運用まで、各フェーズでメンバーと積極的に連携し、スムーズなプロジェクト進行に努めてまいりました。\n",
    "\n",
    "日本語については現在も学習を続けており、**NAT-3 級を取得** しております。日常会話レベルには問題ありませんが、今後さらに語学力を向上させ、日本の開発チームにおいてより円滑なコミュニケーションが図れるよう努力してまいります。\n",
    "\n",
    "日本でのキャリアを通じて、さらなる技術力の向上を目指し、貴社のプロジェクトに貢献できることを心より楽しみにしております。何卒よろしくお願い申し上げます。\n",
    "\n",
    "---\n",
    "\n",
    "✨ **ポイント**  \n",
    "✅ よりフォーマルな表現を使用し、プロフェッショナルな印象にしました。  \n",
    "✅ 技術スキルの具体例を挙げ、実績のインパクトを強調しました。  \n",
    "✅ チームワークと日本語スキルの向上意欲をアピールしました。\n",
    "\n",
    "この自己紹介は面接や職務経歴書にもそのまま使えます。必要に応じてカスタマイズしてください！ 😊\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
