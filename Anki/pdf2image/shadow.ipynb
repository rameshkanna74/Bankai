{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Global objects\n",
    "vectorizer = TfidfVectorizer()\n",
    "scaler = StandardScaler()\n",
    "knn = None\n",
    "\n",
    "@app.route('/train', methods=['POST'])\n",
    "def train_model():\n",
    "    global vectorizer, scaler, knn\n",
    "\n",
    "    # Get file path from the request\n",
    "    file_path = request.json.get('file_path')\n",
    "    if not file_path:\n",
    "        return jsonify({\"error\": \"File path is required\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Read the data\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Ensure numeric column is clean\n",
    "        df[\"matricule_ocr_value\"] = pd.to_numeric(df[\"matricule_ocr_value\"], errors='coerce')\n",
    "\n",
    "        # Drop rows with invalid numeric values\n",
    "        df = df.dropna(subset=[\"matricule_ocr_value\"])\n",
    "\n",
    "        # Extract features and target\n",
    "        X_text = df[\"Full_name\"]\n",
    "        X_numeric = df[\"matricule_ocr_value\"].values.reshape(-1, 1)\n",
    "        y = df[\"Corrected_Name\"]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_text_train, X_text_test, X_numeric_train, X_numeric_test, y_train, y_test = train_test_split(\n",
    "            X_text, X_numeric, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Text feature vectorization\n",
    "        X_text_train_vectors = vectorizer.fit_transform(X_text_train)\n",
    "        X_text_test_vectors = vectorizer.transform(X_text_test)\n",
    "\n",
    "        # Numeric feature scaling\n",
    "        X_numeric_train_scaled = scaler.fit_transform(X_numeric_train)\n",
    "        X_numeric_test_scaled = scaler.transform(X_numeric_test)\n",
    "\n",
    "        # Combine text and numeric features\n",
    "        X_train_combined = np.hstack([X_text_train_vectors.toarray(), X_numeric_train_scaled])\n",
    "        X_test_combined = np.hstack([X_text_test_vectors.toarray(), X_numeric_test_scaled])\n",
    "\n",
    "        # Train KNN model\n",
    "        knn = KNeighborsClassifier(n_neighbors=1)\n",
    "        knn.fit(X_train_combined, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = knn.predict(X_test_combined)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        return jsonify({\"message\": \"Model trained successfully\", \"accuracy\": accuracy})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/predict', methods=['POST', 'GET'])\n",
    "def predict_new_data():\n",
    "    global vectorizer, scaler, knn\n",
    "\n",
    "    if knn is None:\n",
    "        return jsonify({\"error\": \"Model is not trained yet. Please train the model first.\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Get input data from the request\n",
    "        matricule_number = request.json.get('matricule_number')\n",
    "        full_name = request.json.get('full_name')\n",
    "\n",
    "        if matricule_number is None or full_name is None:\n",
    "            return jsonify({\"error\": \"Both matricule_number and full_name are required.\"}), 400\n",
    "\n",
    "        # Transform new text data using the existing vectorizer\n",
    "        new_text_vectors = vectorizer.transform([full_name])\n",
    "\n",
    "        # Scale new numeric data using the existing scaler\n",
    "        new_numeric_scaled = scaler.transform(np.array([matricule_number]).reshape(-1, 1))\n",
    "\n",
    "        # Combine new features\n",
    "        new_combined = np.hstack([new_text_vectors.toarray(), new_numeric_scaled])\n",
    "\n",
    "        # Predict using the trained KNN model\n",
    "        prediction = knn.predict(new_combined)\n",
    "\n",
    "        return jsonify({\n",
    "            \"matricule_number\": matricule_number,\n",
    "            \"full_name\": full_name,\n",
    "            \"predicted_name\": prediction[0]\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚ãªãŸã®è‡ªå·±ç´¹ä»‹ã¯ã™ã§ã«éå¸¸ã«ä¸å¯§ã§å†…å®¹ã‚‚å……å®Ÿã—ã¦ã„ã¾ã™ãŒã€ã•ã‚‰ã«èª­ã¿ã‚„ã™ãã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‹ã¤èª¬å¾—åŠ›ã®ã‚ã‚‹å½¢ã«æ•´ãˆã‚‹ã“ã¨ã§ã€å¤§æ‰‹ãƒ†ãƒƒã‚¯ä¼æ¥­ã¸ã®å°è±¡ã‚’ã‚ˆã‚Šå¼·ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä»¥ä¸‹ã«ã€æ–‡æ³•ã‚„è¡¨ç¾ã‚’ä¿®æ­£ã—ã€èª­ã¿ã‚„ã™ã•ãƒ»è¨´æ±‚åŠ›ãƒ»è‡ªç„¶ãªæ—¥æœ¬èªè¡¨ç¾ã‚’æ„è­˜ã—ãŸæ”¹å–„æ¡ˆã‚’æç¤ºã—ã¾ã™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… ä¿®æ­£ç‰ˆ è‡ªå·±ç´¹ä»‹ï¼ˆå¤§æ‰‹ITä¼æ¥­å‘ã‘ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "åˆã‚ã¾ã—ã¦ã€‚ãƒ©ãƒ¡ã‚·ãƒ¥ãƒ»ã‚«ãƒ³ãƒŠã¨ç”³ã—ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‰ã®ãƒ—ãƒ‰ã‚¥ãƒƒãƒã‚§ãƒªå‡ºèº«ã§ã€ç¾åœ¨ã¯ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–‹ç™ºã‚’å°‚é–€ã¨ã—ã¦ãŠã‚Šã¾ã™ã€‚ä¸»ã« **Python ã‚’ç”¨ã„ãŸ Django ãŠã‚ˆã³ Django REST Framework ã‚’æ´»ç”¨ã—ãŸ REST API é–‹ç™º** ã«å¼·ã¿ã‚’æŒã£ã¦ãŠã‚Šã€**PostgreSQL ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã‚„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**ã«ã‚‚è±Šå¯ŒãªçµŒé¨“ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "ã“ã‚Œã¾ã§ã«ã€OCR API ã‚’çµ±åˆã—ãŸç”»åƒå‡¦ç†ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ã€eãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æ‹…å½“ã—ã€**ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ãƒ»ãƒ­ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã®å®Ÿè£…ã‚’å«ã‚€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–**ã«æ³¨åŠ›ã—ã¦ãã¾ã—ãŸã€‚ã¾ãŸã€**Docker ã‚„ CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ã‚’é€šã˜ã¦ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ä¿å®ˆæ€§ã®å‘ä¸Š**ã«ã‚‚æˆåŠŸã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "ç‰¹ã«ã€EasyOCRã€Google Document AIã€Azure OCR ãªã©è¤‡æ•°ã® OCR ã‚µãƒ¼ãƒ“ã‚¹ã‚’çµ±åˆã—ã€å¤§é‡ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«å‡¦ç†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨­è¨ˆãƒ»é–‹ç™ºã—ãŸå®Ÿç¸¾ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã®çµŒé¨“ã‚’é€šã˜ã¦ã€**é«˜ã„è¨­è¨ˆåŠ›ãƒ»å¯èª­æ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰ãƒ»æ‹¡å¼µæ€§ã®ã‚ã‚‹ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰**ã«è‡ªä¿¡ã‚’æŒã£ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "ç¾åœ¨ã¯ã•ã‚‰ãªã‚‹ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã®ãŸã‚ã« **Rust ã‚’å­¦ç¿’ä¸­**ã§ã‚ã‚Šã€LeetCode ã§ã¯200å•ä»¥ä¸Šã®å•é¡Œã‚’è§£ãã“ã¨ã§ã€**ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«é–¢ã™ã‚‹ç†è§£ã‚’æ·±ã‚ã¦**ãŠã‚Šã¾ã™ã€‚\n",
    "\n",
    "ã¾ãŸã€æŠ€è¡“åŠ›ã ã‘ã§ãªãã€**ãƒãƒ¼ãƒ å†…ã®å††æ»‘ãªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¨é€²åŠ›**ã‚‚ç§ã®å¼·ã¿ã®ä¸€ã¤ã§ã™ã€‚è¦ä»¶å®šç¾©ã‹ã‚‰è¨­è¨ˆã€å®Ÿè£…ã€ãƒ†ã‚¹ãƒˆã€é‹ç”¨ã¾ã§ä¸€è²«ã—ã¦é–¢ã‚ã‚Šã€ãƒãƒ¼ãƒ å…¨ä½“ã®æˆæœæœ€å¤§åŒ–ã«è²¢çŒ®ã—ã¦ã¾ã„ã‚Šã¾ã—ãŸã€‚\n",
    "\n",
    "æ—¥æœ¬èªã«ã¤ã„ã¦ã¯ç¾åœ¨ã‚‚ç¶™ç¶šçš„ã«å­¦ç¿’ä¸­ã§ã‚ã‚Šã€NAT-3ç´šã‚’å–å¾—ã—ã¦ãŠã‚Šã€**æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«ã§ã¯å•é¡Œãªãå¯¾å¿œå¯èƒ½**ã§ã™ã€‚ä»Šå¾Œã•ã‚‰ã«èªå­¦åŠ›ã‚’å‘ä¸Šã•ã›ã€æ—¥æœ¬ã®ä¼æ¥­æ–‡åŒ–ã«ã‚‚ã‚ˆã‚Šæ·±ãè²¢çŒ®ã§ãã‚‹ã‚ˆã†åŠªã‚ã¦ã¾ã„ã‚Šã¾ã™ã€‚\n",
    "\n",
    "å°†æ¥çš„ã«ã¯ã€æ—¥æœ¬ã§ã®ã‚­ãƒ£ãƒªã‚¢ã‚’é€šã˜ã¦ã•ã‚‰ã«æŠ€è¡“åŠ›ã‚’é«˜ã‚ã€ç¤¾ä¼šã«ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’ä¸ãˆã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æºã‚ã£ã¦ã„ããŸã„ã¨è€ƒãˆã¦ãŠã‚Šã¾ã™ã€‚å¾¡ç¤¾ã®ä¸€å“¡ã¨ã—ã¦ã€ä¾¡å€¤ã‚’å‰µå‡ºã§ãã‚‹æ©Ÿä¼šã‚’ã„ãŸã ã‘ã‚Œã°å¤§å¤‰å…‰æ „ã§ã™ã€‚\n",
    "\n",
    "ä½•å’ã€ã‚ˆã‚ã—ããŠé¡˜ã„ç”³ã—ä¸Šã’ã¾ã™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ” æ”¹å–„ãƒã‚¤ãƒ³ãƒˆã®èª¬æ˜ï¼š\n",
    "\n",
    "| å…ƒã®å†…å®¹                   | ä¿®æ­£ãƒ»æ”¹å–„ç†ç”±                       |\n",
    "| ---------------------- | ----------------------------- |\n",
    "| æ–‡ã®é•·ã•ãŒã‚„ã‚„é•·ãã€æƒ…å ±ãŒå¤šã„ãŸã‚èª­ã¿ã«ãã„ | ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«è©±é¡Œã‚’æ˜ç¢ºã«åˆ†ã‘ã€èª­ã¿ã‚„ã™ã•ã‚’é‡è¦–ã—ã¾ã—ãŸ |\n",
    "| ä¸å¯§ã™ãã¦ã‚„ã‚„ç¡¬ã„è¡¨ç¾            | ä¸å¯§ã•ã‚’ä¿ã¡ã¤ã¤ã‚‚è‡ªç„¶ã§ãƒ“ã‚¸ãƒã‚¹ãƒ©ã‚¤ã‚¯ãªæ—¥æœ¬èªã«èª¿æ•´    |\n",
    "| çµŒé¨“ã‚„ã‚¹ã‚­ãƒ«ãŒç¾…åˆ—çš„ã«ãªã£ã¦ã„ãŸ       | å®Ÿç¸¾ã‚„èƒ½åŠ›ãŒéš›ç«‹ã¤ã‚ˆã†ã€æˆæœãƒ™ãƒ¼ã‚¹ã§æ•´ç†          |\n",
    "| æ—¥æœ¬èªå­¦ç¿’ä¸­ã®è¨˜è¿°ãŒå°‘ã—è¬™éœã—ã™ãã¦ã„ãŸ   | è‡ªä¿¡ã¨æ„æ¬²ãŒä¼ã‚ã‚‹è¡¨ç¾ã«å¤‰æ›´                |\n",
    "\n",
    "---\n",
    "\n",
    "ã‚‚ã—å¿œå‹Ÿã™ã‚‹ä¼æ¥­ã®æ¥­ç•Œã‚„æ±‚ã‚ã‚‹ãƒã‚¸ã‚·ãƒ§ãƒ³ãŒåˆ†ã‹ã‚Œã°ã€ã•ã‚‰ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚‚å¯èƒ½ã§ã™ï¼ˆä¾‹ï¼šFinTechã€AIã€IoT ãªã©ï¼‰ã€‚ã¾ãŸã€è‹±æ–‡ç‰ˆã®ç´¹ä»‹æ–‡ãŒå¿…è¦ãªå ´åˆã‚‚å¯¾å¿œã§ãã¾ã™ã€‚ã©ã†ããŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„ï¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
