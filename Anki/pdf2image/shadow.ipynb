{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Global objects\n",
    "vectorizer = TfidfVectorizer()\n",
    "scaler = StandardScaler()\n",
    "knn = None\n",
    "\n",
    "@app.route('/train', methods=['POST'])\n",
    "def train_model():\n",
    "    global vectorizer, scaler, knn\n",
    "\n",
    "    # Get file path from the request\n",
    "    file_path = request.json.get('file_path')\n",
    "    if not file_path:\n",
    "        return jsonify({\"error\": \"File path is required\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Read the data\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Ensure numeric column is clean\n",
    "        df[\"matricule_ocr_value\"] = pd.to_numeric(df[\"matricule_ocr_value\"], errors='coerce')\n",
    "\n",
    "        # Drop rows with invalid numeric values\n",
    "        df = df.dropna(subset=[\"matricule_ocr_value\"])\n",
    "\n",
    "        # Extract features and target\n",
    "        X_text = df[\"Full_name\"]\n",
    "        X_numeric = df[\"matricule_ocr_value\"].values.reshape(-1, 1)\n",
    "        y = df[\"Corrected_Name\"]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_text_train, X_text_test, X_numeric_train, X_numeric_test, y_train, y_test = train_test_split(\n",
    "            X_text, X_numeric, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Text feature vectorization\n",
    "        X_text_train_vectors = vectorizer.fit_transform(X_text_train)\n",
    "        X_text_test_vectors = vectorizer.transform(X_text_test)\n",
    "\n",
    "        # Numeric feature scaling\n",
    "        X_numeric_train_scaled = scaler.fit_transform(X_numeric_train)\n",
    "        X_numeric_test_scaled = scaler.transform(X_numeric_test)\n",
    "\n",
    "        # Combine text and numeric features\n",
    "        X_train_combined = np.hstack([X_text_train_vectors.toarray(), X_numeric_train_scaled])\n",
    "        X_test_combined = np.hstack([X_text_test_vectors.toarray(), X_numeric_test_scaled])\n",
    "\n",
    "        # Train KNN model\n",
    "        knn = KNeighborsClassifier(n_neighbors=1)\n",
    "        knn.fit(X_train_combined, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = knn.predict(X_test_combined)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        return jsonify({\"message\": \"Model trained successfully\", \"accuracy\": accuracy})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/predict', methods=['POST', 'GET'])\n",
    "def predict_new_data():\n",
    "    global vectorizer, scaler, knn\n",
    "\n",
    "    if knn is None:\n",
    "        return jsonify({\"error\": \"Model is not trained yet. Please train the model first.\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Get input data from the request\n",
    "        matricule_number = request.json.get('matricule_number')\n",
    "        full_name = request.json.get('full_name')\n",
    "\n",
    "        if matricule_number is None or full_name is None:\n",
    "            return jsonify({\"error\": \"Both matricule_number and full_name are required.\"}), 400\n",
    "\n",
    "        # Transform new text data using the existing vectorizer\n",
    "        new_text_vectors = vectorizer.transform([full_name])\n",
    "\n",
    "        # Scale new numeric data using the existing scaler\n",
    "        new_numeric_scaled = scaler.transform(np.array([matricule_number]).reshape(-1, 1))\n",
    "\n",
    "        # Combine new features\n",
    "        new_combined = np.hstack([new_text_vectors.toarray(), new_numeric_scaled])\n",
    "\n",
    "        # Predict using the trained KNN model\n",
    "        prediction = knn.predict(new_combined)\n",
    "\n",
    "        return jsonify({\n",
    "            \"matricule_number\": matricule_number,\n",
    "            \"full_name\": full_name,\n",
    "            \"predicted_name\": prediction[0]\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ãƒ•ã‚©ãƒ¼ãƒãƒ«ãªè‡ªå·±ç´¹ä»‹ï¼ˆæ—¥æœ¬èªï¼‰**\n",
    "\n",
    "åˆã‚ã¾ã—ã¦ã€ãƒ©ãƒ¡ã‚·ãƒ¥ãƒ»ã‚«ãƒ³ãƒŠã¨ç”³ã—ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‰ã®ãƒ—ãƒ‰ã‚¥ãƒƒãƒã‚§ãƒªå‡ºèº«ã§ã€ç¾åœ¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–‹ç™ºã‚’å°‚é–€ã¨ã—ã¦ãŠã‚Šã¾ã™ã€‚ç‰¹ã« **Python ã‚’ç”¨ã„ãŸ Django ãŠã‚ˆã³ Django Rest Framework (DRF) ã«ã‚ˆã‚‹ REST API é–‹ç™º** ã«å¼·ã¿ã‚’æŒã¡ã€**PostgreSQL ã‚’æ´»ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–** ã«ã‚‚è±Šå¯ŒãªçµŒé¨“ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "ã“ã‚Œã¾ã§ã®ã‚­ãƒ£ãƒªã‚¢ã«ãŠã„ã¦ã€**OCR API çµ±åˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ e ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–‹ç™º** ã«æºã‚ã‚Šã€**ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ï¼ˆJWT èªè¨¼ï¼‰ã‚„ãƒ­ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ã®å®Ÿè£…** ã‚’æ‹…å½“ã„ãŸã—ã¾ã—ãŸã€‚ã¾ãŸã€**Docker ã‚„ CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ´»ç”¨ã—ãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤** ã‚’è¡Œã„ã€ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ä¿å®ˆæ€§ã®å‘ä¸Šã«ã‚‚è²¢çŒ®ã—ã¦ãŠã‚Šã¾ã™ã€‚\n",
    "\n",
    "ç§ã®å¼·ã¿ã¯ã€**æ‹¡å¼µæ€§ã¨åŠ¹ç‡æ€§ã‚’å…¼ã­å‚™ãˆãŸã‚³ãƒ¼ãƒ‰è¨­è¨ˆ** ã«ã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€å¤§è¦æ¨¡ãª OCR ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã«ãŠã„ã¦ã€**EasyOCRã€Google Document AIã€Azure OCR ãªã©è¤‡æ•°ã® OCR ã‚µãƒ¼ãƒ“ã‚¹ã‚’çµ±åˆã—ã€50,000 ä»¶ä»¥ä¸Šã®ç”»åƒå‡¦ç†ã‚’æœ€é©åŒ–** ã—ãŸå®Ÿç¸¾ãŒã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€ç¾åœ¨ã¯ **Rust ã‚’å­¦ç¿’** ã—ã¦ãŠã‚Šã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç†è§£ã‚’æ·±ã‚ã‚‹ãŸã‚ã€**LeetCode ã§ 200 å•ä»¥ä¸Šã®å•é¡Œã‚’è§£ãã€ä½ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¹ã‚­ãƒ«ã‚’å¼·åŒ–** ã—ã¦ãŠã‚Šã¾ã™ã€‚\n",
    "\n",
    "æŠ€è¡“é¢ã ã‘ã§ãªãã€**ãƒãƒ¼ãƒ ã¨ã®å††æ»‘ãªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³** ã‚‚å¤§åˆ‡ã«ã—ã¦ãŠã‚Šã¾ã™ã€‚è¦ä»¶å®šç¾©ã‹ã‚‰è¨­è¨ˆãƒ»å®Ÿè£…ãƒ»ãƒ†ã‚¹ãƒˆãƒ»é‹ç”¨ã¾ã§ã€å„ãƒ•ã‚§ãƒ¼ã‚ºã§ãƒ¡ãƒ³ãƒãƒ¼ã¨ç©æ¥µçš„ã«é€£æºã—ã€ã‚¹ãƒ ãƒ¼ã‚ºãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé€²è¡Œã«åŠªã‚ã¦ã¾ã„ã‚Šã¾ã—ãŸã€‚\n",
    "\n",
    "æ—¥æœ¬èªã«ã¤ã„ã¦ã¯ç¾åœ¨ã‚‚å­¦ç¿’ã‚’ç¶šã‘ã¦ãŠã‚Šã€**NAT-3 ç´šã‚’å–å¾—** ã—ã¦ãŠã‚Šã¾ã™ã€‚æ—¥å¸¸ä¼šè©±ãƒ¬ãƒ™ãƒ«ã«ã¯å•é¡Œã‚ã‚Šã¾ã›ã‚“ãŒã€ä»Šå¾Œã•ã‚‰ã«èªå­¦åŠ›ã‚’å‘ä¸Šã•ã›ã€æ—¥æœ¬ã®é–‹ç™ºãƒãƒ¼ãƒ ã«ãŠã„ã¦ã‚ˆã‚Šå††æ»‘ãªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒå›³ã‚Œã‚‹ã‚ˆã†åŠªåŠ›ã—ã¦ã¾ã„ã‚Šã¾ã™ã€‚\n",
    "\n",
    "æ—¥æœ¬ã§ã®ã‚­ãƒ£ãƒªã‚¢ã‚’é€šã˜ã¦ã€ã•ã‚‰ãªã‚‹æŠ€è¡“åŠ›ã®å‘ä¸Šã‚’ç›®æŒ‡ã—ã€è²´ç¤¾ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«è²¢çŒ®ã§ãã‚‹ã“ã¨ã‚’å¿ƒã‚ˆã‚Šæ¥½ã—ã¿ã«ã—ã¦ãŠã‚Šã¾ã™ã€‚ä½•å’ã‚ˆã‚ã—ããŠé¡˜ã„ç”³ã—ä¸Šã’ã¾ã™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "âœ¨ **ãƒã‚¤ãƒ³ãƒˆ**  \n",
    "âœ… ã‚ˆã‚Šãƒ•ã‚©ãƒ¼ãƒãƒ«ãªè¡¨ç¾ã‚’ä½¿ç”¨ã—ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªå°è±¡ã«ã—ã¾ã—ãŸã€‚  \n",
    "âœ… æŠ€è¡“ã‚¹ã‚­ãƒ«ã®å…·ä½“ä¾‹ã‚’æŒ™ã’ã€å®Ÿç¸¾ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’å¼·èª¿ã—ã¾ã—ãŸã€‚  \n",
    "âœ… ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨æ—¥æœ¬èªã‚¹ã‚­ãƒ«ã®å‘ä¸Šæ„æ¬²ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã—ã¾ã—ãŸã€‚\n",
    "\n",
    "ã“ã®è‡ªå·±ç´¹ä»‹ã¯é¢æ¥ã‚„è·å‹™çµŒæ­´æ›¸ã«ã‚‚ãã®ã¾ã¾ä½¿ãˆã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ã¦ãã ã•ã„ï¼ ğŸ˜Š\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
