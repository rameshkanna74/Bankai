{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Global objects\n",
    "vectorizer = TfidfVectorizer()\n",
    "scaler = StandardScaler()\n",
    "knn = None\n",
    "\n",
    "@app.route('/train', methods=['POST'])\n",
    "def train_model():\n",
    "    global vectorizer, scaler, knn\n",
    "\n",
    "    # Get file path from the request\n",
    "    file_path = request.json.get('file_path')\n",
    "    if not file_path:\n",
    "        return jsonify({\"error\": \"File path is required\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Read the data\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Ensure numeric column is clean\n",
    "        df[\"matricule_ocr_value\"] = pd.to_numeric(df[\"matricule_ocr_value\"], errors='coerce')\n",
    "\n",
    "        # Drop rows with invalid numeric values\n",
    "        df = df.dropna(subset=[\"matricule_ocr_value\"])\n",
    "\n",
    "        # Extract features and target\n",
    "        X_text = df[\"Full_name\"]\n",
    "        X_numeric = df[\"matricule_ocr_value\"].values.reshape(-1, 1)\n",
    "        y = df[\"Corrected_Name\"]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_text_train, X_text_test, X_numeric_train, X_numeric_test, y_train, y_test = train_test_split(\n",
    "            X_text, X_numeric, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Text feature vectorization\n",
    "        X_text_train_vectors = vectorizer.fit_transform(X_text_train)\n",
    "        X_text_test_vectors = vectorizer.transform(X_text_test)\n",
    "\n",
    "        # Numeric feature scaling\n",
    "        X_numeric_train_scaled = scaler.fit_transform(X_numeric_train)\n",
    "        X_numeric_test_scaled = scaler.transform(X_numeric_test)\n",
    "\n",
    "        # Combine text and numeric features\n",
    "        X_train_combined = np.hstack([X_text_train_vectors.toarray(), X_numeric_train_scaled])\n",
    "        X_test_combined = np.hstack([X_text_test_vectors.toarray(), X_numeric_test_scaled])\n",
    "\n",
    "        # Train KNN model\n",
    "        knn = KNeighborsClassifier(n_neighbors=1)\n",
    "        knn.fit(X_train_combined, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = knn.predict(X_test_combined)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        return jsonify({\"message\": \"Model trained successfully\", \"accuracy\": accuracy})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/predict', methods=['POST', 'GET'])\n",
    "def predict_new_data():\n",
    "    global vectorizer, scaler, knn\n",
    "\n",
    "    if knn is None:\n",
    "        return jsonify({\"error\": \"Model is not trained yet. Please train the model first.\"}), 400\n",
    "\n",
    "    try:\n",
    "        # Get input data from the request\n",
    "        matricule_number = request.json.get('matricule_number')\n",
    "        full_name = request.json.get('full_name')\n",
    "\n",
    "        if matricule_number is None or full_name is None:\n",
    "            return jsonify({\"error\": \"Both matricule_number and full_name are required.\"}), 400\n",
    "\n",
    "        # Transform new text data using the existing vectorizer\n",
    "        new_text_vectors = vectorizer.transform([full_name])\n",
    "\n",
    "        # Scale new numeric data using the existing scaler\n",
    "        new_numeric_scaled = scaler.transform(np.array([matricule_number]).reshape(-1, 1))\n",
    "\n",
    "        # Combine new features\n",
    "        new_combined = np.hstack([new_text_vectors.toarray(), new_numeric_scaled])\n",
    "\n",
    "        # Predict using the trained KNN model\n",
    "        prediction = knn.predict(new_combined)\n",
    "\n",
    "        return jsonify({\n",
    "            \"matricule_number\": matricule_number,\n",
    "            \"full_name\": full_name,\n",
    "            \"predicted_name\": prediction[0]\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あなたの自己紹介はすでに非常に丁寧で内容も充実していますが、さらに読みやすく、プロフェッショナルかつ説得力のある形に整えることで、大手テック企業への印象をより強めることができます。以下に、文法や表現を修正し、読みやすさ・訴求力・自然な日本語表現を意識した改善案を提示します。\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 修正版 自己紹介（大手IT企業向け）\n",
    "\n",
    "---\n",
    "\n",
    "初めまして。ラメシュ・カンナと申します。インドのプドゥッチェリ出身で、現在はバックエンド開発を専門としております。主に **Python を用いた Django および Django REST Framework を活用した REST API 開発** に強みを持っており、**PostgreSQL によるデータベース設計やパフォーマンス最適化**にも豊富な経験があります。\n",
    "\n",
    "これまでに、OCR API を統合した画像処理アプリケーションや、eラーニングプラットフォームのバックエンドを担当し、**ユーザー認証・ロールベースアクセス制御の実装を含むセキュリティ強化**に注力してきました。また、**Docker や CI/CD パイプラインの構築を通じて、アプリケーションのスケーラビリティと保守性の向上**にも成功しています。\n",
    "\n",
    "特に、EasyOCR、Google Document AI、Azure OCR など複数の OCR サービスを統合し、大量の画像データを効率的に処理するシステムを設計・開発した実績があります。これらの経験を通じて、**高い設計力・可読性の高いコード・拡張性のあるシステム構築**に自信を持っています。\n",
    "\n",
    "現在はさらなるスキルアップのために **Rust を学習中**であり、LeetCode では200問以上の問題を解くことで、**アルゴリズムとデータ構造に関する理解を深めて**おります。\n",
    "\n",
    "また、技術力だけでなく、**チーム内の円滑なコミュニケーションやプロジェクト推進力**も私の強みの一つです。要件定義から設計、実装、テスト、運用まで一貫して関わり、チーム全体の成果最大化に貢献してまいりました。\n",
    "\n",
    "日本語については現在も継続的に学習中であり、NAT-3級を取得しており、**日常会話レベルでは問題なく対応可能**です。今後さらに語学力を向上させ、日本の企業文化にもより深く貢献できるよう努めてまいります。\n",
    "\n",
    "将来的には、日本でのキャリアを通じてさらに技術力を高め、社会にインパクトを与えるプロジェクトに携わっていきたいと考えております。御社の一員として、価値を創出できる機会をいただければ大変光栄です。\n",
    "\n",
    "何卒、よろしくお願い申し上げます。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 改善ポイントの説明：\n",
    "\n",
    "| 元の内容                   | 修正・改善理由                       |\n",
    "| ---------------------- | ----------------------------- |\n",
    "| 文の長さがやや長く、情報が多いため読みにくい | セクションごとに話題を明確に分け、読みやすさを重視しました |\n",
    "| 丁寧すぎてやや硬い表現            | 丁寧さを保ちつつも自然でビジネスライクな日本語に調整    |\n",
    "| 経験やスキルが羅列的になっていた       | 実績や能力が際立つよう、成果ベースで整理          |\n",
    "| 日本語学習中の記述が少し謙遜しすぎていた   | 自信と意欲が伝わる表現に変更                |\n",
    "\n",
    "---\n",
    "\n",
    "もし応募する企業の業界や求めるポジションが分かれば、さらにカスタマイズも可能です（例：FinTech、AI、IoT など）。また、英文版の紹介文が必要な場合も対応できます。どうぞお気軽にご相談ください！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
