{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import psycopg\n",
    "# from contextlib import contextmanager\n",
    "\n",
    "\n",
    "# @contextmanager\n",
    "# def get_connection(config):\n",
    "#     \"\"\"\n",
    "#     Context manager to handle PostgreSQL connection lifecycle.\n",
    "#     Ensures that the connection is closed after use.\n",
    "\n",
    "#     :param config: Dictionary containing database connection parameters.\n",
    "#     \"\"\"\n",
    "#     conn = None\n",
    "#     try:\n",
    "#         conn = psycopg.connect(\n",
    "#             dbname=config[\"dbname\"],\n",
    "#             user=config[\"user\"],\n",
    "#             password=config[\"password\"],\n",
    "#             host=config[\"host\"],\n",
    "#             port=config[\"port\"],\n",
    "#         )\n",
    "#         yield conn\n",
    "#         print(f\"Connected to database {config['dbname']} successfully.\")\n",
    "#     except psycopg.OperationalError as e:\n",
    "#         print(f\"Error connecting to database {config['dbname']}: {e}\")\n",
    "#         raise\n",
    "#     finally:\n",
    "#         if conn:\n",
    "#             conn.close()\n",
    "#             print(f\"Connection to database {config['dbname']} closed.\")\n",
    "\n",
    "\n",
    "\n",
    "# def fetch_column_names_for_query(conn, query):\n",
    "#     \"\"\"\n",
    "#     Fetch column names based on the query.\n",
    "\n",
    "#     :param conn: A psycopg connection object.\n",
    "#     :param query: SQL query to analyze.\n",
    "#     :return: A list of column names.\n",
    "#     \"\"\"\n",
    "#     with conn.cursor() as cursor:\n",
    "#         try:\n",
    "#             cursor.execute(f\"SELECT * FROM ({query}) AS subquery LIMIT 0;\")\n",
    "#             return [desc[0] for desc in cursor.description]\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error executing query to fetch column names: {e}\")\n",
    "#             raise\n",
    "\n",
    "\n",
    "# def fetch_data_in_chunks(conn, query, chunk_size=10000, params=None):\n",
    "#     \"\"\"\n",
    "#     Fetch data in chunks to handle large datasets.\n",
    "\n",
    "#     :param conn: A psycopg connection object.\n",
    "#     :param query: SQL query to execute.\n",
    "#     :param chunk_size: Number of rows to fetch per chunk.\n",
    "#     :param params: Optional parameters for the SQL query.\n",
    "#     :return: A generator that yields chunks of data.\n",
    "#     \"\"\"\n",
    "#     with conn.cursor(name=\"data_cursor\") as cursor:\n",
    "#         cursor.execute(query, params)\n",
    "#         while True:\n",
    "#             data = cursor.fetchmany(chunk_size)\n",
    "#             if not data:\n",
    "#                 break\n",
    "#             yield data\n",
    "\n",
    "\n",
    "# def run_query_with_dynamic_columns(db_configs, user_query, chunk_size=10000, params=None):\n",
    "#     \"\"\"\n",
    "#     Execute a user query across multiple databases and return the results as a pandas DataFrame.\n",
    "\n",
    "#     :param db_configs: List of dictionaries containing database connection parameters.\n",
    "#     :param user_query: SQL query provided by the user.\n",
    "#     :param chunk_size: Number of rows to fetch per chunk.\n",
    "#     :param params: Optional parameters for the SQL query.\n",
    "#     :return: A pandas DataFrame with the combined results from all databases.\n",
    "#              The DataFrame includes a column for the database name.\n",
    "#     \"\"\"\n",
    "#     dfs = []\n",
    "\n",
    "#     for config in db_configs:\n",
    "#         try:\n",
    "#             with get_connection(config) as conn:\n",
    "#                 # Fetch the correct column names based on the user query\n",
    "#                 column_names = fetch_column_names_for_query(conn, user_query)\n",
    "\n",
    "#                 # Fetch data in chunks and append to DataFrames list\n",
    "#                 for chunk in fetch_data_in_chunks(conn, user_query, chunk_size, params):\n",
    "#                     if chunk:\n",
    "#                         if len(chunk[0]) != len(column_names):\n",
    "#                             print(f\"Warning: Number of columns in result from {config['dbname']} does not match the provided column names.\")\n",
    "#                             continue\n",
    "\n",
    "#                         df = pd.DataFrame(chunk, columns=column_names)\n",
    "#                         df['database'] = config['dbname']\n",
    "#                         dfs.append(df)\n",
    "#                     else:\n",
    "#                         print(f\"No data returned from {config['dbname']}.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing database {config['dbname']}: {e}\")\n",
    "\n",
    "#     # Concatenate all DataFrames into a single DataFrame\n",
    "#     combined_df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "#     return combined_df\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# db_configs = [\n",
    "#     {\n",
    "#         \"dbname\": \"Employees\",\n",
    "#         \"user\": \"postgres\",\n",
    "#         \"password\": \"root\",\n",
    "#         \"host\": \"localhost\",\n",
    "#         \"port\": \"5432\"\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # Sample query\n",
    "# user_query = \"SELECT * FROM employees ORDER BY emp_no ASC\"  # Adjust the query as needed\n",
    "\n",
    "# # Execute the function\n",
    "# result_df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "# print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import psycopg\n",
    "# from contextlib import contextmanager\n",
    "\n",
    "\n",
    "# @contextmanager\n",
    "# def get_connection(config):\n",
    "#     \"\"\"\n",
    "#     Context manager to handle PostgreSQL connection lifecycle.\n",
    "#     Ensures that the connection is closed after use.\n",
    "\n",
    "#     :param config: Dictionary containing database connection parameters.\n",
    "#     \"\"\"\n",
    "#     conn = None\n",
    "#     try:\n",
    "#         conn = psycopg.connect(\n",
    "#             dbname=config[\"dbname\"],\n",
    "#             user=config[\"user\"],\n",
    "#             password=config[\"password\"],\n",
    "#             host=config[\"host\"],\n",
    "#             port=config[\"port\"],\n",
    "#         )\n",
    "#         yield conn\n",
    "#         print(f\"Connected to database {config['dbname']} successfully.\")\n",
    "#     except psycopg.OperationalError as e:\n",
    "#         print(f\"Error connecting to database {config['dbname']}: {e}\")\n",
    "#         raise\n",
    "#     finally:\n",
    "#         if conn:\n",
    "#             conn.close()\n",
    "#             print(f\"Connection to database {config['dbname']} closed.\")\n",
    "#         else:\n",
    "#             print(f\"Failed to connect to database {config['dbname']}.\")\n",
    "\n",
    "\n",
    "# def fetch_column_names_for_query(conn, query):\n",
    "#     \"\"\"\n",
    "#     Fetch column names based on the query.\n",
    "\n",
    "#     :param conn: A psycopg connection object.\n",
    "#     :param query: SQL query to analyze.\n",
    "#     :return: A list of column names.\n",
    "#     \"\"\"\n",
    "#     with conn.cursor() as cursor:\n",
    "#         try:\n",
    "#             cursor.execute(f\"SELECT * FROM ({query}) AS subquery LIMIT 0;\")\n",
    "#             return [desc[0] for desc in cursor.description]\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error executing query to fetch column names: {e}\")\n",
    "#             raise\n",
    "\n",
    "\n",
    "# def fetch_data_in_chunks(conn, query, chunk_size=10000, params=None):\n",
    "#     \"\"\"\n",
    "#     Fetch data in chunks to handle large datasets.\n",
    "\n",
    "#     :param conn: A psycopg connection object.\n",
    "#     :param query: SQL query to execute.\n",
    "#     :param chunk_size: Number of rows to fetch per chunk.\n",
    "#     :param params: Optional parameters for the SQL query.\n",
    "#     :return: A generator that yields chunks of data.\n",
    "#     \"\"\"\n",
    "#     with conn.cursor(name=\"data_cursor\") as cursor:\n",
    "#         cursor.execute(query, params)\n",
    "#         while True:\n",
    "#             data = cursor.fetchmany(chunk_size)\n",
    "#             if not data:\n",
    "#                 break\n",
    "#             yield data\n",
    "\n",
    "\n",
    "# def run_query_with_dynamic_columns(\n",
    "#     db_configs, user_query, chunk_size=10000, params=None\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Execute a user query across multiple databases and return the results as a pandas DataFrame.\n",
    "\n",
    "#     :param db_configs: List of dictionaries containing database connection parameters.\n",
    "#     :param user_query: SQL query provided by the user.\n",
    "#     :param chunk_size: Number of rows to fetch per chunk.\n",
    "#     :param params: Optional parameters for the SQL query.\n",
    "#     :return: A pandas DataFrame with the combined results from all databases.\n",
    "#              The DataFrame includes a column for the database name.\n",
    "#     \"\"\"\n",
    "#     dfs = []\n",
    "\n",
    "#     for config in db_configs:\n",
    "#         try:\n",
    "#             with get_connection(config) as conn:\n",
    "#                 # Fetch the correct column names based on the user query\n",
    "#                 column_names = fetch_column_names_for_query(conn, user_query)\n",
    "\n",
    "#                 # Fetch data in chunks and append to DataFrames list\n",
    "#                 for chunk in fetch_data_in_chunks(conn, user_query, chunk_size, params):\n",
    "#                     if chunk:\n",
    "#                         # Validate that the number of columns matches the expected number\n",
    "#                         if len(chunk[0]) != len(column_names):\n",
    "#                             print(\n",
    "#                                 f\"Warning: Number of columns in result from {config['dbname']} does not match the provided column names.\"\n",
    "#                             )\n",
    "#                             continue\n",
    "\n",
    "#                         for row in chunk:\n",
    "#                             if len(row) != len(column_names):\n",
    "#                                 print(\n",
    "#                                     f\"Warning: Row length mismatch in {config['dbname']}.\"\n",
    "#                                 )\n",
    "#                                 continue\n",
    "\n",
    "#                         # Create DataFrame and append to the list\n",
    "#                         df = pd.DataFrame(chunk, columns=column_names)\n",
    "#                         # df['database'] = config['dbname']\n",
    "#                         dfs.append(df)\n",
    "#                     else:\n",
    "#                         print(f\"No data returned from {config['dbname']}.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing database {config['dbname']}: {e}\")\n",
    "\n",
    "#     # Concatenate all DataFrames into a single DataFrame\n",
    "#     combined_df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "#     # Log message if no data was retrieved\n",
    "#     if combined_df.empty:\n",
    "#         print(\"No data was retrieved from the databases.\")\n",
    "\n",
    "#     return combined_df\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# db_configs = [\n",
    "#     {\n",
    "#         \"dbname\": \"Employees\",\n",
    "#         \"user\": \"postgres\",\n",
    "#         \"password\": \"root\",\n",
    "#         \"host\": \"localhost\",\n",
    "#         \"port\": \"5432\",\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # Sample query\n",
    "# user_query = \"SELECT * FROM employees ORDER BY emp_no ASC\"  # Adjust the query as needed\n",
    "# params = None  # You can add parameters if needed\n",
    "\n",
    "# # Execute the function\n",
    "# result_df = run_query_with_dynamic_columns(\n",
    "#     db_configs, user_query, chunk_size=10000, params=params\n",
    "# )\n",
    "# print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def get_connection(config):\n",
    "    \"\"\"\n",
    "    Context manager to handle PostgreSQL connection lifecycle.\n",
    "    Ensures that the connection is closed after use.\n",
    "\n",
    "    :param config: Dictionary containing database connection parameters.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg.connect(\n",
    "            dbname=config[\"dbname\"],\n",
    "            user=config[\"user\"],\n",
    "            password=config[\"password\"],\n",
    "            host=config[\"host\"],\n",
    "            port=config[\"port\"],\n",
    "        )\n",
    "        yield conn\n",
    "        print(f\"Connected to database {config['dbname']} successfully.\")\n",
    "    except psycopg.Error as e:\n",
    "        print(f\"Error connecting to database {config['dbname']}: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(f\"Connection to database {config['dbname']} closed.\")\n",
    "        else:\n",
    "            print(f\"Failed to connect to database {config['dbname']}.\")\n",
    "\n",
    "\n",
    "def fetch_column_names_for_query(conn, query):\n",
    "    \"\"\"\n",
    "    Fetch column names based on the query.\n",
    "\n",
    "    :param conn: A psycopg connection object.\n",
    "    :param query: SQL query to analyze.\n",
    "    :return: A list of column names.\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cursor:\n",
    "        try:\n",
    "            cursor.execute(f\"SELECT * FROM ({query}) AS subquery LIMIT 0;\")\n",
    "            return [desc[0] for desc in cursor.description]\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing query to fetch column names: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "def fetch_data_in_chunks(conn, query, chunk_size=10000, params=None):\n",
    "    \"\"\"\n",
    "    Fetch data in chunks to handle large datasets.\n",
    "\n",
    "    :param conn: A psycopg connection object.\n",
    "    :param query: SQL query to execute.\n",
    "    :param chunk_size: Number of rows to fetch per chunk.\n",
    "    :param params: Optional parameters for the SQL query.\n",
    "    :return: A generator that yields chunks of data.\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(query, params)\n",
    "        while True:\n",
    "            data = cursor.fetchmany(chunk_size)\n",
    "            if not data:\n",
    "                break\n",
    "            yield data\n",
    "\n",
    "\n",
    "def run_query_with_dynamic_columns(\n",
    "    db_configs, user_query, chunk_size=10000, params=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Execute a user query across multiple databases and return the results as a pandas DataFrame.\n",
    "\n",
    "    :param db_configs: List of dictionaries containing database connection parameters.\n",
    "    :param user_query: SQL query provided by the user.\n",
    "    :param chunk_size: Number of rows to fetch per chunk.\n",
    "    :param params: Optional parameters for the SQL query.\n",
    "    :return: A pandas DataFrame with the combined results from all databases.\n",
    "             The DataFrame includes a column for the database name.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    for config in db_configs:\n",
    "        try:\n",
    "            with get_connection(config) as conn:\n",
    "                # Fetch the correct column names based on the user query\n",
    "                column_names = fetch_column_names_for_query(conn, user_query)\n",
    "\n",
    "                # Fetch data in chunks and append to DataFrames list\n",
    "                for chunk in fetch_data_in_chunks(conn, user_query, chunk_size, params):\n",
    "                    if chunk:\n",
    "                        # Validate that the number of columns matches the expected number\n",
    "                        if len(chunk[0]) != len(column_names):\n",
    "                            print(\n",
    "                                f\"Warning: Number of columns in result from {config['dbname']} does not match the provided column names.\"\n",
    "                            )\n",
    "                            continue\n",
    "\n",
    "                        for row in chunk:\n",
    "                            if len(row) != len(column_names):\n",
    "                                print(\n",
    "                                    f\"Warning: Row length mismatch in {config['dbname']}.\"\n",
    "                                )\n",
    "                                continue\n",
    "\n",
    "                        # Create DataFrame and append to the list\n",
    "                        df = pd.DataFrame(chunk, columns=column_names)\n",
    "                        df['database'] = config['dbname']  # Add the database name as a column\n",
    "                        dfs.append(df)\n",
    "                    else:\n",
    "                        print(f\"No data returned from {config['dbname']}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing database {config['dbname']}: {e}\")\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "    # Log message if no data was retrieved\n",
    "    if combined_df.empty:\n",
    "        print(\"No data was retrieved from the databases.\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "db_configs = [\n",
    "    {\n",
    "        \"dbname\": \"Employees\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"root\",\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": \"5432\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sample query\n",
    "user_query = \"SELECT * FROM employees ORDER BY emp_no ASC\"  # Adjust the query as needed\n",
    "params = None  # You can add parameters if needed\n",
    "\n",
    "# Execute the function\n",
    "result_df = run_query_with_dynamic_columns(\n",
    "    db_configs, user_query, chunk_size=10000, params=params\n",
    ")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"SELECT emp_no AS \"Employee #\" FROM \"employees\" ORDER BY emp_no ASC\"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"SELECT emp_no AS \"Employee #\", birth_date AS \"Birthday\", first_name AS \"First name\" FROM \"employees\" ORDER BY emp_no ASC\"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"SELECT * FROM \"employees\" ORDER BY emp_no ASC\"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"SELECT CONCAT(emp_no, ' is a ', title) AS \"Employee Title\" FROM \"titles\" ORDER BY emp_no ASC\"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"SELECT CONCAT(first_name, ' ', last_name) AS \"Name\" FROM \"employees\" ORDER BY emp_no ASC\"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"SELECT COUNT(emp_no) FROM \"employees\" \"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"SELECT max(emp_no) FROM \"employees\" \"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"SELECT MAX(salary) FROM \"salaries\" \"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"\n",
    "                SELECT SUM(salary)\n",
    "                FROM \"salaries\" \n",
    "             \"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"\n",
    "               -- select statement to filter Mayumi Schueller\n",
    "               SELECT *\n",
    "               FROM \"employees\"\n",
    "               /*\n",
    "               filter on first name AND last name to limit the amount of data returned\n",
    "               and focus the filtering on a single person\n",
    "               */\n",
    "               WHERE first_name = 'Mayumi' AND last_name = 'Schueller' -- filter here on Mayumi Schueller\n",
    "             \"\"\"\n",
    "\n",
    "# SQL comments[single line]\n",
    "# -- filter on first name AND last name to limit the amount of data returned\n",
    "# -- and focus the filtering on a single person\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"\n",
    "               SELECT *\n",
    "               FROM \"employees\"\n",
    "               WHERE \"gender\" = 'F'\n",
    "             \"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the table name and the user's query\n",
    "user_query = \"\"\"SELECT * FROM employees ORDER BY emp_no DESC\"\"\"  # Adjust the query as needed\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"SELECT column_name FROM information_schema.columns  WHERE table_name = 'employees'\"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"\"\"\n",
    "SELECT\n",
    "    table_schema,\n",
    "    table_name,\n",
    "    column_name,\n",
    "    ordinal_position,\n",
    "    is_nullable,\n",
    "    data_type,\n",
    "    character_maximum_length,\n",
    "    numeric_precision,\n",
    "    numeric_scale,\n",
    "    datetime_precision\n",
    "FROM\n",
    "    information_schema.columns\n",
    "WHERE\n",
    "    table_schema NOT IN ('information_schema', 'pg_catalog')  -- Exclude system schemas\n",
    "ORDER BY\n",
    "    table_schema,\n",
    "    table_name,\n",
    "    ordinal_position\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"\"\"\n",
    "WITH DepartmentSalaries AS (\n",
    "    -- Subquery to get the average salary per department\n",
    "    SELECT\n",
    "        d.dept_no,\n",
    "        d.dept_name,\n",
    "        AVG(s.salary) AS avg_salary\n",
    "    FROM\n",
    "        departments d\n",
    "    JOIN\n",
    "        dept_emp de ON d.dept_no = de.dept_no\n",
    "    JOIN\n",
    "        salaries s ON de.emp_no = s.emp_no\n",
    "    GROUP BY\n",
    "        d.dept_no, d.dept_name\n",
    "),\n",
    "EmployeeSalaries AS (\n",
    "    -- Subquery to get employee details with their salaries and departments\n",
    "    SELECT\n",
    "        e.emp_no,\n",
    "        e.first_name,\n",
    "        e.last_name,\n",
    "        e.gender,\n",
    "        e.hire_date,\n",
    "        t.title,\n",
    "        de.dept_no,\n",
    "        d.dept_name,\n",
    "        s.salary,\n",
    "        ROW_NUMBER() OVER (PARTITION BY de.dept_no ORDER BY s.salary DESC) AS salary_rank\n",
    "    FROM\n",
    "        employees e\n",
    "    JOIN\n",
    "        salaries s ON e.emp_no = s.emp_no\n",
    "    JOIN\n",
    "        titles t ON e.emp_no = t.emp_no\n",
    "    JOIN\n",
    "        dept_emp de ON e.emp_no = de.emp_no\n",
    "    JOIN\n",
    "        departments d ON de.dept_no = d.dept_no\n",
    "    WHERE\n",
    "        s.to_date = '9999-01-01'  -- Only current salaries\n",
    "    AND\n",
    "        t.to_date = '9999-01-01'  -- Only current titles\n",
    "),\n",
    "TopSalaries AS (\n",
    "    -- Subquery to get the highest-earning employee in each department\n",
    "    SELECT\n",
    "        dept_no,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        salary,\n",
    "        dept_name,\n",
    "        title,\n",
    "        salary_rank\n",
    "    FROM\n",
    "        EmployeeSalaries\n",
    "    WHERE\n",
    "        salary_rank = 1\n",
    ")\n",
    "-- Final query to get the desired results\n",
    "SELECT\n",
    "    es.emp_no,\n",
    "    es.first_name,\n",
    "    es.last_name,\n",
    "    es.title,\n",
    "    es.dept_name,\n",
    "    es.salary,\n",
    "    es.salary_rank,\n",
    "    ds.avg_salary,\n",
    "    CASE\n",
    "        WHEN es.salary > ds.avg_salary THEN 'Above Average'\n",
    "        WHEN es.salary = ds.avg_salary THEN 'Average'\n",
    "        ELSE 'Below Average'\n",
    "    END AS salary_comparison\n",
    "FROM\n",
    "    EmployeeSalaries es\n",
    "JOIN\n",
    "    DepartmentSalaries ds ON es.dept_no = ds.dept_no\n",
    "ORDER BY\n",
    "    es.dept_name,\n",
    "    es.salary_rank\n",
    "\"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"\n",
    "SELECT * FROM employees \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "# print(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distribution\n",
    "gender_counts = df['gender'].value_counts()\n",
    "\n",
    "# Pie chart\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=140, colors=['skyblue', 'pink'])\n",
    "plt.title('Gender Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert hire_date to datetime\n",
    "df['hire_date'] = pd.to_datetime(df['hire_date'])\n",
    "\n",
    "# Histogram of hire dates\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['hire_date'].dt.year.hist(bins=20, color='orange', edgecolor='black')\n",
    "plt.title('Hire Date Distribution')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Employees')\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ages\n",
    "current_year = pd.Timestamp.now().year\n",
    "df['age'] = current_year - pd.to_datetime(df['birth_date']).dt.year\n",
    "\n",
    "# Box plot of ages\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(df['age'], vert=False, patch_artist=True, boxprops=dict(facecolor='lightgreen'))\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the user's query\n",
    "user_query = \"\"\"\n",
    "SELECT * FROM salaries \n",
    "\"\"\"\n",
    "# Run the function with the user query\n",
    "salary_df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "# print(df)\n",
    "salary_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Calculate age\n",
    "current_year = pd.Timestamp.now().year\n",
    "df['age'] = current_year - pd.to_datetime(df['birth_date']).dt.year\n",
    "df['salary']= salary_df['salary']\n",
    "\n",
    "# Scatter plot of Salary vs Age\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='age', y='salary', hue='gender', palette={'M': 'blue', 'F': 'pink'}, s=100, alpha=0.7)\n",
    "plt.title('Salary vs Age with Gender Hue', fontsize=16)\n",
    "plt.xlabel('Age', fontsize=14)\n",
    "plt.ylabel('Salary ($)', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by salary and take top N employees\n",
    "top_n = 10\n",
    "top_earners = df.nlargest(top_n, 'salary')\n",
    "\n",
    "# Horizontal bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_earners['first_name'] + ' ' + top_earners['last_name'], top_earners['salary'], color='teal')\n",
    "plt.title(f'Top {top_n} Employees by Salary', fontsize=16)\n",
    "plt.xlabel('Salary ($)', fontsize=14)\n",
    "plt.ylabel('Employee Name', fontsize=14)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show highest salary on top\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=df, x='gender', y='age', palette={'M': 'blue', 'F': 'pink'})\n",
    "plt.title('Age Distribution by Gender', fontsize=16)\n",
    "plt.xlabel('Gender', fontsize=14)\n",
    "plt.ylabel('Age', fontsize=14)\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year and month\n",
    "df['hire_year'] = df['hire_date'].dt.year\n",
    "df['hire_month'] = df['hire_date'].dt.month\n",
    "\n",
    "# Create pivot table for heatmap\n",
    "hire_heatmap_data = df.pivot_table(index='hire_month', columns='hire_year', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(hire_heatmap_data, cmap='Blues', annot=True, fmt='d', linewidths=.5)\n",
    "plt.title('Number of Hires by Year and Month', fontsize=16)\n",
    "plt.xlabel('Hire Year', fontsize=14)\n",
    "plt.ylabel('Hire Month', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(data=df, x='age', y='salary', scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "plt.title('Age vs Salary Regression Plot', fontsize=16)\n",
    "plt.xlabel('Age', fontsize=14)\n",
    "plt.ylabel('Salary ($)', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate birth decade\n",
    "df['birth_decade'] = (pd.to_datetime(df['birth_date']).dt.year // 10) * 10\n",
    "\n",
    "# Group data\n",
    "decade_gender = df.groupby(['birth_decade', 'gender']).size().unstack()\n",
    "\n",
    "# Stacked bar chart\n",
    "decade_gender.plot(kind='bar', stacked=True, figsize=(12, 6), color=['blue', 'pink'])\n",
    "plt.title('Employee Counts by Birth Decade', fontsize=16)\n",
    "plt.xlabel('Birth Decade', fontsize=14)\n",
    "plt.ylabel('Number of Employees', fontsize=14)\n",
    "plt.legend(title='Gender')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='gender', y='salary', palette={'M': 'blue', 'F': 'pink'})\n",
    "plt.title('Salary Distribution by Gender', fontsize=16)\n",
    "plt.xlabel('Gender', fontsize=14)\n",
    "plt.ylabel('Salary ($)', fontsize=14)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from hire_date\n",
    "df['hire_year'] = pd.to_datetime(df['hire_date']).dt.year\n",
    "\n",
    "# Group by hire year\n",
    "hires_by_year = df['hire_year'].value_counts().sort_index()\n",
    "\n",
    "# Line plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(hires_by_year.index, hires_by_year.values, marker='o', linestyle='-', color='darkorange')\n",
    "plt.title('Hire Trend Over Time', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Number of Employees Hired', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentiles\n",
    "salary_percentiles = df['salary'].quantile([0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "# Filled line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.fill_between([1, 2, 3, 4], salary_percentiles, color='skyblue', alpha=0.5, label='Salary Range')\n",
    "plt.plot([1, 2, 3, 4], salary_percentiles, color='blue', marker='o')\n",
    "plt.xticks([1, 2, 3, 4], ['25%', '50%', '75%', '100%'])\n",
    "plt.title('Salary Percentiles', fontsize=16)\n",
    "plt.xlabel('Percentile', fontsize=14)\n",
    "plt.ylabel('Salary ($)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=df, x='salary', fill=True, color='purple', alpha=0.5)\n",
    "plt.title('Salary Distribution (KDE)', fontsize=16)\n",
    "plt.xlabel('Salary ($)', fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "numeric_df = df[['age', 'salary']]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort salaries\n",
    "sorted_salaries = df['salary'].sort_values()\n",
    "\n",
    "# Compute cumulative percentages\n",
    "cumulative = sorted_salaries.cumsum() / sorted_salaries.sum()\n",
    "\n",
    "# CDF plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sorted_salaries, cumulative, color='green', marker='o', linestyle='-', alpha=0.7)\n",
    "plt.title('Salary Cumulative Distribution', fontsize=16)\n",
    "plt.xlabel('Salary ($)', fontsize=14)\n",
    "plt.ylabel('Cumulative Percentage', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot for selected numeric columns\n",
    "sns.pairplot(df[['age', 'salary']], diag_kind='kde', plot_kws={'alpha': 0.6}, diag_kws={'fill': True})\n",
    "plt.suptitle('Pair Plot of Age and Salary', y=1.02, fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate years of experience\n",
    "df['experience'] = current_year - pd.to_datetime(df['hire_date']).dt.year\n",
    "\n",
    "# Bin experience into categories\n",
    "bins = [0, 5, 10, 20, 30, 50]\n",
    "labels = ['0-5', '6-10', '11-20', '21-30', '31+']\n",
    "df['experience_group'] = pd.cut(df['experience'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Pie chart\n",
    "experience_counts = df['experience_group'].value_counts()\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(experience_counts, labels=experience_counts.index, autopct='%1.1f%%', colors=sns.color_palette(\"pastel\"))\n",
    "plt.title('Employee Experience Levels', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming department data is available in `df_dept` and can be joined\n",
    "\n",
    "user_query = \"\"\"\n",
    "SELECT d.dept_name, AVG(s.salary) as avg_salary\n",
    "FROM salaries s\n",
    "JOIN dept_emp de ON s.emp_no = de.emp_no\n",
    "JOIN departments d ON de.dept_no = d.dept_no\n",
    "WHERE s.to_date = '9999-01-01'\n",
    "GROUP BY d.dept_name\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Run the function with the user query\n",
    "dept_salary_df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "\n",
    "# Bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Top Departments by Average Salary\", fontsize=16)\n",
    "# sns.barplot(data=dept_salary_df, x=\"avg_salary\", y=\"dept_name\", palette=\"coolwarm\")\n",
    "sns.barplot(\n",
    "    data=dept_salary_df,\n",
    "    x=\"avg_salary\",\n",
    "    y=\"dept_name\",\n",
    "    hue=\"dept_name\",  # Explicitly set hue to match y-variable\n",
    "    dodge=False,  # Avoid splitting bars\n",
    "    palette=\"coolwarm\",\n",
    ")\n",
    "plt.legend([], [], frameon=False)  # Hide the legend\n",
    "\n",
    "plt.xlabel(\"Average Salary ($)\", fontsize=14)\n",
    "plt.ylabel(\"Department\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the user's query\n",
    "user_query = \"\"\"\n",
    "SELECT * FROM salaries \n",
    "\"\"\"\n",
    "# Run the function with the user query\n",
    "salary_df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "# print(df)\n",
    "salary_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the user's query\n",
    "user_query = \"\"\"\n",
    "SELECT * FROM salaries \n",
    "\"\"\"\n",
    "# Run the function with the user query\n",
    "salary_df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "# print(df)\n",
    "salary_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
