{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing query to fetch column names: column \"department\" does not exist\n",
      "LINE 3:     SELECT department, COUNT(emp_no) AS num_employees\n",
      "                   ^\n",
      "Connection to database Employees closed.\n",
      "Error processing database Employees: column \"department\" does not exist\n",
      "LINE 3:     SELECT department, COUNT(emp_no) AS num_employees\n",
      "                   ^\n",
      "No data was retrieved from the databases.\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import psycopg\n",
    "# from contextlib import contextmanager\n",
    "\n",
    "\n",
    "# @contextmanager\n",
    "# def get_connection(config):\n",
    "#     \"\"\"\n",
    "#     Context manager to handle PostgreSQL connection lifecycle.\n",
    "#     Ensures that the connection is closed after use.\n",
    "#     \"\"\"\n",
    "#     conn = None\n",
    "#     try:\n",
    "#         conn = psycopg.connect(\n",
    "#             dbname=config[\"dbname\"],\n",
    "#             user=config[\"user\"],\n",
    "#             password=config[\"password\"],\n",
    "#             host=config[\"host\"],\n",
    "#             port=config[\"port\"],\n",
    "#         )\n",
    "#         yield conn\n",
    "#         print(f\"Connected to database {config['dbname']} successfully.\")\n",
    "#     except psycopg.OperationalError as e:\n",
    "#         print(f\"Error connecting to database {config['dbname']}: {e}\")\n",
    "#         raise\n",
    "#     finally:\n",
    "#         if conn:\n",
    "#             conn.close()\n",
    "#             print(f\"Connection to database {config['dbname']} closed.\")\n",
    "#         else:\n",
    "#             print(f\"Failed to connect to database {config['dbname']}.\")\n",
    "\n",
    "\n",
    "# def fetch_column_names_for_query(conn, query):\n",
    "#     \"\"\"\n",
    "#     Fetch column names based on the query, supporting complex queries like CTEs, joins, and window functions.\n",
    "    \n",
    "#     :param conn: A psycopg connection object.\n",
    "#     :param query: SQL query to analyze.\n",
    "#     :return: A list of column names.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Execute the query with LIMIT 0 to avoid fetching rows and only get column names\n",
    "#         with conn.cursor() as cursor:\n",
    "#             cursor.execute(f\"{query} LIMIT 0;\")\n",
    "#             return [desc[0] for desc in cursor.description]\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error executing query to fetch column names: {e}\")\n",
    "#         raise\n",
    "\n",
    "\n",
    "# def fetch_data_in_chunks(conn, query, chunk_size=10000, params=None):\n",
    "#     \"\"\"\n",
    "#     Fetch data in chunks to handle large datasets.\n",
    "\n",
    "#     :param conn: A psycopg connection object.\n",
    "#     :param query: SQL query to execute.\n",
    "#     :param chunk_size: Number of rows to fetch per chunk.\n",
    "#     :param params: Optional parameters for the SQL query.\n",
    "#     :return: A generator that yields chunks of data.\n",
    "#     \"\"\"\n",
    "#     with conn.cursor(name=\"data_cursor\") as cursor:\n",
    "#         cursor.execute(query, params)\n",
    "#         while True:\n",
    "#             data = cursor.fetchmany(chunk_size)\n",
    "#             if not data:\n",
    "#                 break\n",
    "#             yield data\n",
    "\n",
    "\n",
    "# def run_query_with_dynamic_columns(db_configs, user_query, chunk_size=10000, params=None):\n",
    "#     \"\"\"\n",
    "#     Execute a user query across multiple databases and return the results as a pandas DataFrame.\n",
    "\n",
    "#     :param db_configs: List of dictionaries containing database connection parameters.\n",
    "#     :param user_query: SQL query provided by the user.\n",
    "#     :param chunk_size: Number of rows to fetch per chunk.\n",
    "#     :param params: Optional parameters for the SQL query.\n",
    "#     :return: A pandas DataFrame with the combined results from all databases.\n",
    "#              The DataFrame includes a column for the database name.\n",
    "#     \"\"\"\n",
    "#     dfs = []\n",
    "\n",
    "#     for config in db_configs:\n",
    "#         try:\n",
    "#             with get_connection(config) as conn:\n",
    "#                 # Fetch the correct column names based on the user query\n",
    "#                 column_names = fetch_column_names_for_query(conn, user_query)\n",
    "\n",
    "#                 # Fetch data in chunks and append to DataFrames list\n",
    "#                 for chunk in fetch_data_in_chunks(conn, user_query, chunk_size, params):\n",
    "#                     if chunk:\n",
    "#                         # Validate that the number of columns matches the expected number\n",
    "#                         if len(chunk[0]) != len(column_names):\n",
    "#                             print(f\"Warning: Number of columns in result from {config['dbname']} does not match the provided column names.\")\n",
    "#                             continue\n",
    "\n",
    "#                         for row in chunk:\n",
    "#                             if len(row) != len(column_names):\n",
    "#                                 print(f\"Warning: Row length mismatch in {config['dbname']}.\")\n",
    "#                                 continue\n",
    "\n",
    "#                         # Create DataFrame and append to the list\n",
    "#                         df = pd.DataFrame(chunk, columns=column_names)\n",
    "#                         dfs.append(df)\n",
    "#                     else:\n",
    "#                         print(f\"No data returned from {config['dbname']}.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing database {config['dbname']}: {e}\")\n",
    "\n",
    "#     # Concatenate all DataFrames into a single DataFrame\n",
    "#     combined_df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "#     # Log message if no data was retrieved\n",
    "#     if combined_df.empty:\n",
    "#         print(\"No data was retrieved from the databases.\")\n",
    "    \n",
    "#     return combined_df\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# db_configs = [\n",
    "#     {\n",
    "#         \"dbname\": \"Employees\",\n",
    "#         \"user\": \"postgres\",\n",
    "#         \"password\": \"root\",\n",
    "#         \"host\": \"localhost\",\n",
    "#         \"port\": \"5432\"\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # Sample advanced query (with CTE and window function)\n",
    "# user_query = \"\"\"\n",
    "# WITH department_summary AS (\n",
    "#     SELECT department, COUNT(emp_no) AS num_employees\n",
    "#     FROM employees\n",
    "#     GROUP BY department\n",
    "# )\n",
    "# SELECT e.emp_no, e.name, d.department, d.num_employees,\n",
    "#        ROW_NUMBER() OVER (PARTITION BY d.department ORDER BY e.emp_no) AS row_num\n",
    "# FROM employees e\n",
    "# JOIN department_summary d ON e.department = d.department\n",
    "# ORDER BY d.department, e.emp_no\n",
    "# \"\"\" \n",
    "\n",
    "# params = None  # You can add parameters if needed\n",
    "\n",
    "# # Execute the function\n",
    "# result_df = run_query_with_dynamic_columns(db_configs, user_query, chunk_size=10000, params=params)\n",
    "# print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing query to fetch column names: column \"department\" does not exist\n",
      "LINE 3:     SELECT department, COUNT(emp_no) AS num_employees\n",
      "                   ^\n",
      "Connection to database Employees closed.\n",
      "Error processing database Employees: column \"department\" does not exist\n",
      "LINE 3:     SELECT department, COUNT(emp_no) AS num_employees\n",
      "                   ^\n",
      "No data was retrieved from the databases.\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def get_connection(config):\n",
    "    \"\"\"\n",
    "    Context manager to handle PostgreSQL connection lifecycle.\n",
    "    Ensures that the connection is closed after use.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg.connect(\n",
    "            dbname=config[\"dbname\"],\n",
    "            user=config[\"user\"],\n",
    "            password=config[\"password\"],\n",
    "            host=config[\"host\"],\n",
    "            port=config[\"port\"],\n",
    "        )\n",
    "        yield conn\n",
    "        print(f\"Connected to database {config['dbname']} successfully.\")\n",
    "    except psycopg.OperationalError as e:\n",
    "        print(f\"Error connecting to database {config['dbname']}: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(f\"Connection to database {config['dbname']} closed.\")\n",
    "        else:\n",
    "            print(f\"Failed to connect to database {config['dbname']}.\")\n",
    "\n",
    "\n",
    "def fetch_data_in_chunks(conn, query, chunk_size=10000, params=None):\n",
    "    \"\"\"\n",
    "    Fetch data in chunks to handle large datasets.\n",
    "\n",
    "    :param conn: A psycopg connection object.\n",
    "    :param query: SQL query to execute.\n",
    "    :param chunk_size: Number of rows to fetch per chunk.\n",
    "    :param params: Optional parameters for the SQL query.\n",
    "    :return: A generator that yields chunks of data.\n",
    "    \"\"\"\n",
    "    with conn.cursor(name=\"data_cursor\") as cursor:\n",
    "        cursor.execute(query, params)\n",
    "        while True:\n",
    "            data = cursor.fetchmany(chunk_size)\n",
    "            if not data:\n",
    "                break\n",
    "            yield data\n",
    "\n",
    "\n",
    "def fetch_column_names_for_query(conn, query):\n",
    "    \"\"\"\n",
    "    Fetch column names based on the query, supporting complex queries like CTEs, joins, and window functions.\n",
    "    \n",
    "    :param conn: A psycopg connection object.\n",
    "    :param query: SQL query to analyze.\n",
    "    :return: A list of column names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a simple query that selects no rows to fetch column names\n",
    "        base_query = f\"EXPLAIN (FORMAT JSON) {query}\"\n",
    "        \n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(base_query)\n",
    "            explain_result = cursor.fetchone()\n",
    "\n",
    "            # Get the output plan from the EXPLAIN result\n",
    "            if explain_result:\n",
    "                # Extract the column names from the plan\n",
    "                plan = explain_result[0]\n",
    "                column_names = plan[0].get(\"Plan\", {}).get(\"Output\", [])\n",
    "                print(f\"Column names extracted: {column_names}\")  # Debug print statement\n",
    "                return column_names\n",
    "            else:\n",
    "                print(\"Failed to retrieve column names using EXPLAIN.\")\n",
    "                return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query to fetch column names: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def run_query_with_dynamic_columns(db_configs, user_query, chunk_size=10000, params=None):\n",
    "    \"\"\"\n",
    "    Execute a user query across multiple databases and return the results as a pandas DataFrame.\n",
    "\n",
    "    :param db_configs: List of dictionaries containing database connection parameters.\n",
    "    :param user_query: SQL query provided by the user.\n",
    "    :param chunk_size: Number of rows to fetch per chunk.\n",
    "    :param params: Optional parameters for the SQL query.\n",
    "    :return: A pandas DataFrame with the combined results from all databases.\n",
    "             The DataFrame includes a column for the database name.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    for config in db_configs:\n",
    "        try:\n",
    "            with get_connection(config) as conn:\n",
    "                # Fetch the correct column names based on the user query\n",
    "                column_names = fetch_column_names_for_query(conn, user_query)\n",
    "\n",
    "                # Fetch data in chunks and append to DataFrames list\n",
    "                for chunk in fetch_data_in_chunks(conn, user_query, chunk_size, params):\n",
    "                    if chunk:\n",
    "                        # Debug: Print the number of columns in the current chunk\n",
    "                        print(f\"Number of columns in chunk: {len(chunk[0])}\")  # Debug print statement\n",
    "                        \n",
    "                        # Validate that the number of columns matches the expected number\n",
    "                        if len(chunk[0]) != len(column_names):\n",
    "                            print(f\"Warning: Number of columns in result from {config['dbname']} does not match the provided column names.\")\n",
    "                            print(f\"Expected {len(column_names)} columns, but got {len(chunk[0])} columns.\")  # Debug print statement\n",
    "                            continue\n",
    "\n",
    "                        for row in chunk:\n",
    "                            if len(row) != len(column_names):\n",
    "                                print(f\"Warning: Row length mismatch in {config['dbname']}.\")\n",
    "                                continue\n",
    "\n",
    "                        # Create DataFrame and append to the list\n",
    "                        df = pd.DataFrame(chunk, columns=column_names)\n",
    "                        # Optionally, add a column to identify the source database\n",
    "                        df['database'] = config['dbname']\n",
    "                        dfs.append(df)\n",
    "                    else:\n",
    "                        print(f\"No data returned from {config['dbname']}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing database {config['dbname']}: {e}\")\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "    # Log message if no data was retrieved\n",
    "    if combined_df.empty:\n",
    "        print(\"No data was retrieved from the databases.\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "db_configs = [\n",
    "    {\n",
    "        \"dbname\": \"Employees\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"root\",\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": \"5432\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sample advanced query (with CTE and window function)\n",
    "user_query = \"\"\"\n",
    "WITH department_summary AS (\n",
    "    SELECT department, COUNT(emp_no) AS num_employees\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    ")\n",
    "SELECT e.emp_no, e.name, d.department, d.num_employees,\n",
    "       ROW_NUMBER() OVER (PARTITION BY d.department ORDER BY e.emp_no) AS row_num\n",
    "FROM employees e\n",
    "JOIN department_summary d ON e.department = d.department\n",
    "ORDER BY d.department, e.emp_no\n",
    "\"\"\"\n",
    "\n",
    "params = None  # You can add parameters if needed\n",
    "\n",
    "# Execute the function\n",
    "result_df = run_query_with_dynamic_columns(\n",
    "    db_configs, user_query, chunk_size=10000, params=params\n",
    ")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names extracted: []\n",
      "Number of columns in chunk: 1\n",
      "Warning: Number of columns in result from Employees does not match the provided column names.\n",
      "Expected 0 columns, but got 1 columns.\n",
      "Connected to database Employees successfully.\n",
      "Connection to database Employees closed.\n",
      "No data was retrieved from the databases.\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Define the user's query\n",
    "user_query = \"\"\"SELECT column_name\n",
    "        FROM information_schema.columns\n",
    "    WHERE table_name = 'employees';\n",
    "\"\"\"\n",
    "\n",
    "# Run the function with the user query\n",
    "df = run_query_with_dynamic_columns(db_configs, user_query)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bankai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
